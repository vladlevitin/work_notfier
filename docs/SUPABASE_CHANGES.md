# âœ… Supabase Integration Complete!

## What's Been Changed:

### 1. **Config File for Facebook Groups** ğŸ“
- **File**: `config.py`
- **Purpose**: Centralized list of Facebook groups to scrape
- **How to add groups**: Just add URLs to the `FACEBOOK_GROUPS` list

```python
FACEBOOK_GROUPS = [
    "https://www.facebook.com/groups/2014558715497143",
    "https://www.facebook.com/groups/857134597636986",
    # Add more here!
]
```

---

### 2. **Supabase Database** â˜ï¸
- **Replaced**: SQLite (`facebook_posts.db`)
- **New**: Cloud PostgreSQL database via Supabase
- **File**: `supabase_db.py` - All database operations
- **Schema**: `supabase_schema.sql` - Run this in Supabase SQL Editor

**Advantages:**
- âœ… Cloud-hosted (access from anywhere)
- âœ… Real-time updates
- âœ… Automatic backups
- âœ… Scalable for many posts
- âœ… Web UI to browse data

---

### 3. **Upload ALL Posts** ğŸ“Š
**Old behavior:**
- Only saved posts matching driving/moving keywords
- Many posts were ignored

**New behavior:**
- **Scrapes and saves ALL posts** from Facebook groups (5 scrolls each)
- Filters keywords AFTER saving to database
- Only sends email for NEW posts matching keywords
- No duplicates (checks `post_id`)

**Workflow:**
1. Scrape ALL posts from Facebook â†’ Save to Supabase
2. Filter for keyword matches
3. Check if matched posts are NEW (not yet notified)
4. Send email ONLY for new relevant posts
5. Mark as notified in database

---

### 4. **Updated Files**

#### **main.py**
- Uses `config.py` for Facebook groups list
- Uses `supabase_db.py` instead of `database.py`
- Displays database stats before scraping
- Better logging and progress tracking

#### **backend/app/api/posts.py**
- Updated to use `supabase_db.py`
- All API endpoints work with Supabase

#### **requirements.txt**
- Added: `supabase` (Python Supabase client)

#### **.env.example**
- Template for required environment variables
- Includes Supabase URL and Key

---

## ğŸš€ How to Use:

### First Time Setup:

1. **Follow SUPABASE_SETUP.md** to:
   - Create Supabase project
   - Run SQL schema
   - Get API credentials
   - Update `.env` file

2. **Install new dependency:**
   ```bash
   pip install supabase
   ```

3. **Test connection:**
   ```bash
   python supabase_db.py
   ```

### Running the Scraper:

```bash
python main.py
```

**What it does:**
1. Connects to Supabase
2. Shows current database stats
3. Loops through Facebook groups in `config.py`
4. Scrapes 5 scrolls per group (configurable in `config.py`)
5. Saves **ALL posts** to Supabase (no duplicates)
6. Filters for keyword matches
7. Sends email for NEW relevant posts
8. Marks notified posts in database

### Adding More Facebook Groups:

Edit `config.py`:

```python
FACEBOOK_GROUPS = [
    "https://www.facebook.com/groups/2014558715497143",
    "https://www.facebook.com/groups/857134597636986",
    "https://www.facebook.com/groups/YOUR_NEW_GROUP_ID",  # Add here!
]

SCROLL_STEPS_PER_GROUP = 5  # Change to scrape more/less
```

### Viewing Dashboard:

The dashboard will show ALL posts from Supabase once deployed!

---

## ğŸ“‚ File Structure:

```
work_notifier/
â”œâ”€â”€ config.py                   # âœ¨ NEW: Facebook groups list
â”œâ”€â”€ supabase_db.py             # âœ¨ NEW: Supabase database operations
â”œâ”€â”€ supabase_schema.sql        # âœ¨ NEW: Database schema
â”œâ”€â”€ .env.example               # âœ¨ NEW: Environment variables template
â”œâ”€â”€ SUPABASE_SETUP.md          # âœ¨ NEW: Setup instructions
â”œâ”€â”€ main.py                    # âœ¨ UPDATED: Uses Supabase & config
â”œâ”€â”€ backend/app/api/posts.py   # âœ¨ UPDATED: Uses Supabase
â”œâ”€â”€ requirements.txt           # âœ¨ UPDATED: Added supabase
â”œâ”€â”€ scraper.py                 # (unchanged)
â”œâ”€â”€ email_notifier.py          # (unchanged)
â”œâ”€â”€ browser_manager.py         # (unchanged)
â””â”€â”€ frontend/                  # (works with Supabase via API)
```

---

## ğŸ¯ Key Changes Summary:

### What's New:
âœ… **Supabase cloud database** instead of local SQLite  
âœ… **Config file** for easy Facebook group management  
âœ… **Upload ALL posts** (not just keyword matches)  
âœ… **Better logging** and progress tracking  
âœ… **Scalable architecture** for production use  

### What Stays the Same:
âœ… Email notifications for matching posts  
âœ… Keyword filtering  
âœ… Duplicate prevention  
âœ… React dashboard  
âœ… Human-like scraping behavior  

---

## ğŸ”§ Environment Variables Needed:

Update your `.env` file:

```env
# Microsoft Graph API (Email)
TENANT_ID=your_tenant_id
CLIENT_ID=your_client_id
CLIENT_SECRET=your_client_secret
SENDER_EMAIL=your_email@example.com

# Supabase (NEW!)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=your_supabase_anon_key
```

---

## ğŸ‰ You're Ready!

1. Follow `SUPABASE_SETUP.md` to set up Supabase
2. Run `pip install supabase`
3. Update your `.env` with Supabase credentials
4. Run `python main.py` to start scraping

**All posts will be stored in Supabase cloud database!** â˜ï¸
